#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script ƒë·ªÉ s·∫Øp x·∫øp l·∫°i kho t√†i li·ªáu c√° nh√¢n
Lo·∫°i b·ªè file tr√πng l·∫∑p v√† t·ªï ch·ª©c theo c·∫•u tr√∫c th·ªëng nh·∫•t
"""

import os
import shutil
import hashlib
import json
from pathlib import Path
from datetime import datetime

class FileOrganizer:
    def __init__(self, base_path):
        self.base_path = Path(base_path)
        self.duplicates = {}
        self.file_hashes = {}
        self.stats = {
            'moved': 0,
            'duplicates': 0,
            'errors': 0,
            'processed': 0
        }

    def calculate_file_hash(self, file_path):
        """T√≠nh hash MD5 c·ªßa file ƒë·ªÉ ph√°t hi·ªán tr√πng l·∫∑p"""
        try:
            with open(file_path, 'rb') as f:
                return hashlib.md5(f.read()).hexdigest()
        except Exception as e:
            print(f"L·ªói khi t√≠nh hash {file_path}: {e}")
            return None

    def find_duplicates(self):
        """T√¨m c√°c file tr√πng l·∫∑p trong to√†n b·ªô workspace"""
        print("üîç ƒêang t√¨m file tr√πng l·∫∑p...")

        # Duy·ªát qua t·∫•t c·∫£ file
        for root, dirs, files in os.walk(self.base_path):
            # B·ªè qua th∆∞ m·ª•c .git v√† c√°c th∆∞ m·ª•c kh√¥ng c·∫ßn thi·∫øt
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['__pycache__', 'node_modules']]

            for file in files:
                if file.endswith('.md'):
                    file_path = Path(root) / file
                    file_hash = self.calculate_file_hash(file_path)

                    if file_hash:
                        if file_hash in self.file_hashes:
                            # File tr√πng l·∫∑p
                            if file_hash not in self.duplicates:
                                self.duplicates[file_hash] = [self.file_hashes[file_hash]]
                            self.duplicates[file_hash].append(file_path)
                        else:
                            self.file_hashes[file_hash] = file_path

        print(f"üìä T√¨m th·∫•y {len(self.duplicates)} nh√≥m file tr√πng l·∫∑p")

    def move_to_organized_structure(self):
        """Di chuy·ªÉn file v√†o c·∫•u tr√∫c Organized_Docs"""
        organized_path = self.base_path / "Organized_Docs"

        # ƒê·∫£m b·∫£o th∆∞ m·ª•c ƒë√≠ch t·ªìn t·∫°i
        organized_path.mkdir(exist_ok=True)

        print("üìÅ ƒêang s·∫Øp x·∫øp file...")

        # Di chuy·ªÉn file t·ª´ c√°c th∆∞ m·ª•c s·ªë th·ª© t·ª±
        source_dirs = ['01_AI_Tools', '02_OSINT_Tools', '03_Security_Hacking_Tools', '04_Documentation', 'AI_Tools', 'Security_Tools']

        for source_dir in source_dirs:
            source_path = self.base_path / source_dir
            if source_path.exists():
                print(f"  ‚Ü≥ ƒêang x·ª≠ l√Ω {source_dir}...")

                for file_path in source_path.rglob('*.md'):
                    if file_path.is_file():
                        self.move_file_to_category(file_path, organized_path)
                        self.stats['processed'] += 1

        # X·ª≠ l√Ω c√°c th∆∞ m·ª•c kh√°c
        other_dirs = ['Other', 'Technology', 'Tutorials']
        for other_dir in other_dirs:
            other_path = self.base_path / other_dir
            if other_path.exists():
                print(f"  ‚Ü≥ ƒêang x·ª≠ l√Ω {other_dir}...")

                for file_path in other_path.rglob('*.md'):
                    if file_path.is_file():
                        self.move_file_to_category(file_path, organized_path)
                        self.stats['processed'] += 1

    def move_file_to_category(self, file_path, organized_path):
        """Di chuy·ªÉn file v√†o th∆∞ m·ª•c ph√π h·ª£p"""
        try:
            # ƒê·ªçc n·ªôi dung file ƒë·ªÉ x√°c ƒë·ªãnh ch·ªß ƒë·ªÅ
            content = ""
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read(1000)  # ƒê·ªçc 1000 k√Ω t·ª± ƒë·∫ßu
            except:
                try:
                    with open(file_path, 'r', encoding='gbk') as f:
                        content = f.read(1000)
                except:
                    content = file_path.name

            # X√°c ƒë·ªãnh th∆∞ m·ª•c ƒë√≠ch d·ª±a tr√™n n·ªôi dung
            target_dir = self.categorize_file(content, file_path.name)

            # T·∫°o th∆∞ m·ª•c ƒë√≠ch
            target_path = organized_path / target_dir
            target_path.mkdir(exist_ok=True)

            # T·∫°o t√™n file m·ªõi (th√™m timestamp ƒë·ªÉ tr√°nh tr√πng l·∫∑p)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            new_filename = f"{timestamp}_{file_path.name}"
            new_path = target_path / new_filename

            # Di chuy·ªÉn file
            shutil.move(str(file_path), str(new_path))
            self.stats['moved'] += 1

            print(f"    ‚úì {file_path.name} ‚Üí {target_dir}/{new_filename}")

        except Exception as e:
            print(f"    ‚úó L·ªói khi di chuy·ªÉn {file_path}: {e}")
            self.stats['errors'] += 1

    def categorize_file(self, content, filename):
        """Ph√¢n lo·∫°i file d·ª±a tr√™n n·ªôi dung v√† t√™n file"""
        content_lower = content.lower()
        filename_lower = filename.lower()

        # AI & Machine Learning
        ai_keywords = ['ai', 'artificial intelligence', 'machine learning', 'deep learning', 'chatgpt', 'claude', 'gemini', 'gpt', 'llm', 'chatbot']
        if any(keyword in content_lower or keyword in filename_lower for keyword in ai_keywords):
            return "AI_HocMay"

        # Network Security
        security_keywords = ['security', 'hacking', 'penetration', 'vulnerability', 'exploit', 'malware', 'virus', 'trojan', 'phishing', 'hacker', 'pentest']
        if any(keyword in content_lower or keyword in filename_lower for keyword in security_keywords):
            return "BaoMatMang"

        # OSINT
        osint_keywords = ['osint', 'intelligence', 'reconnaissance', 'facebook', 'tiktok', 'social media', 'username', 'email', 'phone']
        if any(keyword in content_lower or keyword in filename_lower for keyword in osint_keywords):
            return "PhatTrien"  # OSINT tools s·∫Ω v√†o PhatTrien

        # Development
        dev_keywords = ['programming', 'development', 'web', 'app', 'software', 'code', 'javascript', 'python', 'java', 'github']
        if any(keyword in content_lower or keyword in filename_lower for keyword in dev_keywords):
            return "PhatTrien"

        # Cloud & Infrastructure
        cloud_keywords = ['cloud', 'aws', 'azure', 'google cloud', 'docker', 'kubernetes', 'serverless', 'infrastructure']
        if any(keyword in content_lower or keyword in filename_lower for keyword in cloud_keywords):
            return "DamMay_HaTang"

        # Data Science
        data_keywords = ['data science', 'dataset', 'machine learning', 'statistics', 'python', 'pandas', 'numpy', 'matplotlib']
        if any(keyword in content_lower or keyword in filename_lower for keyword in data_keywords):
            return "KhoaHocDuLieu"

        # Default category
        return "HuongDan_TongHop"

    def remove_duplicate_files(self):
        """X√≥a c√°c file tr√πng l·∫∑p, gi·ªØ l·∫°i file trong Organized_Docs"""
        print("üóëÔ∏è ƒêang x√≥a file tr√πng l·∫∑p...")

        organized_path = self.base_path / "Organized_Docs"

        for hash_value, file_paths in self.duplicates.items():
            # Gi·ªØ l·∫°i file trong Organized_Docs, x√≥a c√°c file kh√°c
            organized_files = [p for p in file_paths if str(organized_path) in str(p)]
            other_files = [p for p in file_paths if str(organized_path) not in str(p)]

            if organized_files:
                # C√≥ file trong Organized_Docs, x√≥a c√°c file kh√°c
                for file_path in other_files:
                    try:
                        if file_path.exists():
                            os.remove(file_path)
                            self.stats['duplicates'] += 1
                            print(f"    üóëÔ∏è ƒê√£ x√≥a file tr√πng l·∫∑p: {file_path}")
                    except Exception as e:
                        print(f"    ‚úó L·ªói khi x√≥a {file_path}: {e}")
            else:
                # Kh√¥ng c√≥ file trong Organized_Docs, gi·ªØ l·∫°i file ƒë·∫ßu ti√™n
                for file_path in file_paths[1:]:
                    try:
                        if file_path.exists():
                            os.remove(file_path)
                            self.stats['duplicates'] += 1
                            print(f"    üóëÔ∏è ƒê√£ x√≥a file tr√πng l·∫∑p: {file_path}")
                    except Exception as e:
                        print(f"    ‚úó L·ªói khi x√≥a {file_path}: {e}")

    def clean_empty_directories(self):
        """X√≥a c√°c th∆∞ m·ª•c tr·ªëng"""
        print("üßπ ƒêang d·ªçn d·∫πp th∆∞ m·ª•c tr·ªëng...")

        for root, dirs, files in os.walk(self.base_path, topdown=False):
            for dir_name in dirs:
                dir_path = Path(root) / dir_name
                try:
                    if not any(dir_path.rglob('*')):
                        dir_path.rmdir()
                        print(f"    üóëÔ∏è ƒê√£ x√≥a th∆∞ m·ª•c tr·ªëng: {dir_path}")
                except:
                    pass

    def generate_readme(self):
        """T·∫°o README.md m·ªõi cho t·ª´ng th∆∞ m·ª•c"""
        organized_path = self.base_path / "Organized_Docs"

        categories = {
            "AI_HocMay": {
                "title": "ü§ñ AI & H·ªçc M√°y",
                "description": "C√°c t√†i li·ªáu v·ªÅ tr√≠ tu·ªá nh√¢n t·∫°o v√† h·ªçc m√°y",
                "topics": ["ChatGPT", "Claude", "Gemini", "AI Tools", "Machine Learning"]
            },
            "BaoMatMang": {
                "title": "üõ°Ô∏è B·∫£o M·∫≠t M·∫°ng",
                "description": "C√°c t√†i li·ªáu v·ªÅ b·∫£o m·∫≠t v√† an ninh m·∫°ng",
                "topics": ["Penetration Testing", "Vulnerability", "Malware", "Network Security"]
            },
            "PhatTrien": {
                "title": "üíª Ph√°t Tri·ªÉn Ph·∫ßn M·ªÅm",
                "description": "C√°c t√†i li·ªáu v·ªÅ ph√°t tri·ªÉn ph·∫ßn m·ªÅm",
                "topics": ["Web Development", "OSINT Tools", "GitHub Projects", "Programming"]
            },
            "DamMay_HaTang": {
                "title": "‚òÅÔ∏è ƒê√°m M√¢y & H·∫° T·∫ßng",
                "description": "C√°c t√†i li·ªáu v·ªÅ ƒë√°m m√¢y v√† h·∫° t·∫ßng",
                "topics": ["AWS", "Google Cloud", "Docker", "Kubernetes"]
            },
            "KhoaHocDuLieu": {
                "title": "üìä Khoa H·ªçc D·ªØ Li·ªáu",
                "description": "C√°c t√†i li·ªáu v·ªÅ khoa h·ªçc d·ªØ li·ªáu",
                "topics": ["Python", "Datasets", "Machine Learning", "Statistics"]
            },
            "HuongDan_TongHop": {
                "title": "üìö H∆∞·ªõng D·∫´n T·ªïng H·ª£p",
                "description": "C√°c h∆∞·ªõng d·∫´n v√† t√†i li·ªáu t·ªïng h·ª£p",
                "topics": ["Tutorials", "Guides", "Documentation"]
            }
        }

        # T·∫°o README cho t·ª´ng th∆∞ m·ª•c
        for category, info in categories.items():
            category_path = organized_path / category
            if category_path.exists():
                readme_path = category_path / "README.md"

                # ƒê·∫øm s·ªë file
                md_files = list(category_path.glob("*.md"))
                file_count = len([f for f in md_files if f.name != "README.md"])

                # T·∫°o n·ªôi dung README
                readme_content = f"""# {info['title']}

{info['description']}

## üìä Th√¥ng Tin
- **S·ªë l∆∞·ª£ng file**: {file_count} files
- **C·∫≠p nh·∫≠t**: {datetime.now().strftime('%d/%m/%Y')}

## üìã Ch·ªß ƒê·ªÅ Ch√≠nh
"""

                for topic in info['topics']:
                    readme_content += f"- {topic}\n"

                readme_content += "\n## üìÅ Danh S√°ch Files\n\n"

                # Li·ªát k√™ c√°c file
                for md_file in sorted(md_files):
                    if md_file.name != "README.md":
                        readme_content += f"- [{md_file.name}]({md_file.name})\n"

                readme_content += "\n---\n*T·ª± ƒë·ªông t·∫°o b·ªüi File Organizer*"

                # Ghi file
                with open(readme_path, 'w', encoding='utf-8') as f:
                    f.write(readme_content)

                print(f"    ‚úì ƒê√£ t·∫°o README cho {category}")

        # T·∫°o README t·ªïng th·ªÉ
        total_files = sum(len(list((organized_path / cat).glob("*.md"))) for cat in categories.keys() if (organized_path / cat).exists())

        main_readme = f"""# üìÅ Kho T√†i Li·ªáu C√° Nh√¢n - ƒê√£ S·∫Øp X·∫øp

Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi kho t√†i li·ªáu c√° nh√¢n ƒë√£ ƒë∆∞·ª£c s·∫Øp x·∫øp theo ch·ªß ƒë·ªÅ!

## üìÇ C·∫•u Tr√∫c Th∆∞ M·ª•c

"""

        for category, info in categories.items():
            category_path = organized_path / category
            if category_path.exists():
                file_count = len([f for f in category_path.glob("*.md") if f.name != "README.md"])
                main_readme += f"### {info['title']} ({file_count} files)\n"
                main_readme += f"{info['description']}\n\n"
                main_readme += f"**Ch·ªß ƒë·ªÅ:** {', '.join(info['topics'])}\n\n"

        main_readme += f"""## üìä Th·ªëng K√™
- **T·ªïng s·ªë file**: {total_files} files
- **S·ªë th∆∞ m·ª•c**: {len(categories)} categories
- **ƒê√£ s·∫Øp x·∫øp**: ‚úÖ Ho√†n th√†nh
- **C·∫≠p nh·∫≠t g·∫ßn nh·∫•t**: {datetime.now().strftime('%d/%m/%Y')}

## üîç C√°ch S·ª≠ Dung
1. Ch·ªçn th∆∞ m·ª•c theo ch·ªß ƒë·ªÅ b·∫°n quan t√¢m
2. ƒê·ªçc README.md trong t·ª´ng th∆∞ m·ª•c ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt
3. Duy·ªát qua c√°c file markdown
4. S·ª≠ d·ª•ng t√¨m ki·∫øm ƒë·ªÉ t√¨m n·ªôi dung c·ª• th·ªÉ

---
*T·ª± ƒë·ªông s·∫Øp x·∫øp b·ªüi File Organizer v√†o {datetime.now().strftime('%d/%m/%Y %H:%M')}*
"""

        with open(organized_path / "README.md", 'w', encoding='utf-8') as f:
            f.write(main_readme)

        print("    ‚úì ƒê√£ t·∫°o README t·ªïng th·ªÉ")

    def run(self):
        """Ch·∫°y to√†n b·ªô qu√° tr√¨nh s·∫Øp x·∫øp"""
        print("üöÄ B·∫Øt ƒë·∫ßu s·∫Øp x·∫øp kho t√†i li·ªáu...")
        print("=" * 50)

        # B∆∞·ªõc 1: T√¨m file tr√πng l·∫∑p
        self.find_duplicates()

        # B∆∞·ªõc 2: Di chuy·ªÉn file v√†o c·∫•u tr√∫c m·ªõi
        self.move_to_organized_structure()

        # B∆∞·ªõc 3: X√≥a file tr√πng l·∫∑p
        self.remove_duplicate_files()

        # B∆∞·ªõc 4: D·ªçn d·∫πp th∆∞ m·ª•c tr·ªëng
        self.clean_empty_directories()

        # B∆∞·ªõc 5: T·∫°o README
        self.generate_readme()

        # In th·ªëng k√™
        print("=" * 50)
        print("üìä TH·ªêNG K√ä HO√ÄN TH√ÄNH:")
        print(f"  ‚Ä¢ ƒê√£ x·ª≠ l√Ω: {self.stats['processed']} files")
        print(f"  ‚Ä¢ ƒê√£ di chuy·ªÉn: {self.stats['moved']} files")
        print(f"  ‚Ä¢ ƒê√£ x√≥a tr√πng l·∫∑p: {self.stats['duplicates']} files")
        print(f"  ‚Ä¢ L·ªói: {self.stats['errors']} files")
        print("=" * 50)
        print("‚úÖ Ho√†n th√†nh s·∫Øp x·∫øp kho t√†i li·ªáu!")

if __name__ == "__main__":
    organizer = FileOrganizer("D:/T√ÄI LI√äU/Personal_Knowledge_Base")
    organizer.run()
